# Generative Compilation

This project evaluates the code compilation and optimization capabilities of large language models. In particular, it focuses on the compilation of C source units to assembly language and the optimization of that assembly.

## Motivation

With the rapid advancement of machine learning models, specifically large language models like GPT-4, the boundaries of what these models can accomplish are continuously expanding. Traditionally, tasks like code compilation and optimization were exclusively the domain of dedicated software like compilers. This project aims to explore the frontier of what large language models can achieve in the realm of code compilation and optimization. By pitting these models against traditional compilers, we can gauge the potential of AI in this domain, understand its limitations, and envision future collaboration between traditional software and AI models.
	
## Approach

The project's methodology can be broken down into the following steps:

1. **Technique Identification:** Recognize simple optimization techniques typically employed by C compilers.
2. **Problem Generation with GPT-4:** Leverage GPT-4 to create coding challenges. Each challenge consists of a C compilation unit that is prime for optimization using the identified techniques.
3. **Compilation with Clang:** Generate assembly code for the provided problems using Clang at various optimization settings, notably `-O0`, where optimizations are turned off.
4. **Test Generation with GPT-4:** Task GPT-4 with creating tests for each coding problem. These tests will validate the answers against both GPT-generated Python functions and the Clang-produced assembly.
5. **Optimization by LLM:** Request the large language model (LLM) to refine the unoptimized assembly churned out by Clang. The improved assembly will then be confirmed using the generated tests.
6. **Direct Assembly Generation by LLM:** Without any guidance from Clang, the LLM will be asked to produce its assembly for the problem. This assembly will be validated using the generated tests.
7. **Performance Measurement:** Quantify the CPU time for both the Clang-generated and LLM-produced assembly implementations. This will be achieved using a test driver that runs the assembly a configurable number of times.
8. **Performance Comparison:** Contrast the efficiency of each implementation to derive insights about the LLM's optimization capabilities.

## Language Models Used

Throughout this project, different iterations of OpenAI's GPT series of technologies were evaluated:

- **GPT-4:** This was the primary model used due to its advanced capabilities and the availability of its Advanced Data Analysis mode.
- **GPT-3.5:** While it was tested, GPT-3.5 exhibited challenges in consistently reasoning about assembly language, leading to its exclusion from the core evaluations.
- **OpenAI API:** The API was not utilized because direct access to GPT-4's Advanced Data Analysis mode proved more beneficial for the project's objectives.

## Getting Started

1. **Generate Problems** (Optional):
	The repository already contains generated problems. To generate new problems in the same format, use the prompt style in [LINK](prompts/problem_generation.txt).

2. **Generate Solutions**:
	Run the following command, which generates solutions for each problem. When input is needed from the LLM, it outputs the prompt to `stdout` and reads the response from `stdin`.
	
	If a compilation, linking, or testing error occurs with the assembly generated by the LLM, the script provides the error to the LLM and asks for corrected assembly.
	
	```bash
	python3 generate_solutions.py problems
	```

7. **Profile the Solutions** (Optional):
	If you wish to profile the performance of the solutions, run:
	```bash
	python3 profile_solutions.py problems
	```

8. **Visualize Results** (Optional):
	After testing and profiling, you can visualize the results using:
	```bash
	python3 visualize_results.py problems analysis
	```
	
	This will generate performance graphs for each problem in the `analysis` subdirectory.
